{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### reference https://www.kaggle.com/code/yamsam/recbole-gru4rec-sample-code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成原子文件 atomic file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cudf\n",
    "import gc\n",
    "import datetime\n",
    "import polars as pl\n",
    "IS_TRAIN = True\n",
    "\n",
    "if IS_TRAIN:\n",
    "    train = cudf.read_parquet('/root/autodl-tmp/ottodata/valid/train.parquet')\n",
    "    last_week_time = train['ts'].max() - 7 * 24 * 3600\n",
    "    train = train[train['ts']>last_week_time]\n",
    "    test = cudf.read_parquet('/root/autodl-tmp/ottodata/valid/test.parquet')\n",
    "    data_dir = '/root/autodl-tmp/ottodata/tmp/gru_train/'\n",
    "else:\n",
    "    train = cudf.read_parquet('/root/autodl-tmp/ottodata/train.parquet')\n",
    "    last_week_time = train['ts'].max() - 7 * 24 * 3600\n",
    "    train = train[train['ts']>last_week_time]\n",
    "    test = cudf.read_parquet('/root/autodl-tmp/ottodata/test.parquet')\n",
    "    data_dir = '/root/autodl-tmp/ottodata/tmp/gru_test/'\n",
    "\n",
    "df = cudf.concat([train, test])\n",
    "df = pl.from_pandas(df.to_pandas())\n",
    "# test = pl.read_parquet('../data/test.parquet')\n",
    "# valid2 = pl.read_parquet('../data/valid2.parquet')\n",
    "# valid3 = pl.read_parquet('../data/valid3.parquet')\n",
    "\n",
    "# print (f\"       test  : before={datetime.datetime.fromtimestamp(test['ts'].min())} - {datetime.datetime.fromtimestamp(test['ts'].max())}\")\n",
    "# print (f\"     valid2  : before={datetime.datetime.fromtimestamp(valid2['ts'].min())} - {datetime.datetime.fromtimestamp(valid2['ts'].max())}\")\n",
    "# print (f\"     valid3  : before={datetime.datetime.fromtimestamp(valid3['ts'].min())} - {datetime.datetime.fromtimestamp(valid3['ts'].max())}\")\n",
    "\n",
    "# df = pl.concat([valid2, valid3, test])  # 拼接起来一起训练模型\n",
    "# del test, valid2, valid3\n",
    " \n",
    "df = df.sort(['session', 'aid', 'ts'])\n",
    "df = df.with_columns((pl.col('ts') * 1e9).alias('ts'))\n",
    "df = df.rename({'session': 'session:token', 'aid': 'aid:token', 'ts': 'ts:float'})\n",
    "if not os.path.exists(f'{data_dir}/gru'):\n",
    "    os.makedirs(f'{data_dir}/gru')\n",
    "df['session:token', 'aid:token', 'ts:float',].write_csv(f'{data_dir}/gru/gru.inter', sep='\\t')\n",
    "del df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练gru模型的参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!\n",
    "MAX_ITEM = 20   #  每个用户的aid数量，用于粗排和embedding计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parameter_dict = {\n",
    "    'data_path': data_dir,\n",
    "    'USER_ID_FIELD':'session',\n",
    "    'ITEM_ID_FIELD': 'aid',\n",
    "    'TIME_FIELD': 'ts',\n",
    "    'user_inter_num_interval': \"[5,Inf)\",\n",
    "    'item_inter_num_interval': \"[5,Inf)\",\n",
    "    'load_col': {\n",
    "        'inter': \n",
    "            ['session', 'aid', 'ts']\n",
    "                },\n",
    "#    'train_neg_sample_args': None,\n",
    "\n",
    "    'save_dataset':True,\n",
    "    'save_dataloaders':True,\n",
    "    # 'dataloaders_save_path':'.，/data/gru',\n",
    "    # 'dataset_save_path':'.，/data/gru',\n",
    "    'checkpoint_dir': f'{data_dir}/gru/',  \n",
    "\n",
    "    'epochs': 10,\n",
    "    'stopping_step':3,\n",
    "    'loss_type':'BPR',\n",
    "    'eval_batch_size': 1024,\n",
    "    #'train_batch_size': 1024,\n",
    "#    'enable_amp':True,\n",
    "    'MAX_ITEM_LIST_LENGTH': MAX_ITEM,   #########\n",
    "    'eval_args': {\n",
    "        'split': {'RS': [9, 1, 0]},\n",
    "        'group_by': 'user',\n",
    "        'order': 'TO',\n",
    "        'mode': 'full'},\n",
    "    'topk': [20, 200],\n",
    "    'valid_metric': 'Recall@200'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28 Jan 17:32    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = /root/autodl-tmp/ottodata/tmp/gru_train/gru\n",
      "checkpoint_dir = /root/autodl-tmp/ottodata/tmp/gru_train//gru/\n",
      "show_progress = True\n",
      "save_dataset = True\n",
      "dataset_save_path = None\n",
      "save_dataloaders = True\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 10\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "neg_sampling = {'uniform': 1}\n",
      "eval_step = 1\n",
      "stopping_step = 3\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [9, 1, 0]}, 'group_by': 'user', 'order': 'TO', 'mode': 'full'}\n",
      "repeatable = True\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [20, 200]\n",
      "valid_metric = Recall@200\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 1024\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = session\n",
      "ITEM_ID_FIELD = aid\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = ts\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['session', 'aid', 'ts']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [5,Inf)\n",
      "item_inter_num_interval = [5,Inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 20\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "wandb_project = recbole\n",
      "require_pow = False\n",
      "embedding_size = 64\n",
      "hidden_size = 128\n",
      "num_layers = 1\n",
      "dropout_prob = 0.3\n",
      "loss_type = BPR\n",
      "MODEL_TYPE = ModelType.SEQUENTIAL\n",
      "MODEL_INPUT_TYPE = InputType.PAIRWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "device = cuda\n",
      "train_neg_sample_args = {'strategy': 'by', 'by': 1, 'distribution': 'uniform', 'dynamic': 'none'}\n",
      "eval_neg_sample_args = {'strategy': 'full', 'distribution': 'uniform'}\n",
      "\n",
      "\n",
      "\n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = /root/autodl-tmp/ottodata/tmp/gru_train/gru\n",
      "checkpoint_dir = /root/autodl-tmp/ottodata/tmp/gru_train//gru/\n",
      "show_progress = True\n",
      "save_dataset = True\n",
      "dataset_save_path = None\n",
      "save_dataloaders = True\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 10\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "neg_sampling = {'uniform': 1}\n",
      "eval_step = 1\n",
      "stopping_step = 3\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [9, 1, 0]}, 'group_by': 'user', 'order': 'TO', 'mode': 'full'}\n",
      "repeatable = True\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [20, 200]\n",
      "valid_metric = Recall@200\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 1024\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = session\n",
      "ITEM_ID_FIELD = aid\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = ts\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['session', 'aid', 'ts']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [5,Inf)\n",
      "item_inter_num_interval = [5,Inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 20\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "wandb_project = recbole\n",
      "require_pow = False\n",
      "embedding_size = 64\n",
      "hidden_size = 128\n",
      "num_layers = 1\n",
      "dropout_prob = 0.3\n",
      "loss_type = BPR\n",
      "MODEL_TYPE = ModelType.SEQUENTIAL\n",
      "MODEL_INPUT_TYPE = InputType.PAIRWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "device = cuda\n",
      "train_neg_sample_args = {'strategy': 'by', 'by': 1, 'distribution': 'uniform', 'dynamic': 'none'}\n",
      "eval_neg_sample_args = {'strategy': 'full', 'distribution': 'uniform'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from recbole.quick_start import load_data_and_model\n",
    "from typing import List, Tuple\n",
    "from pydantic import BaseModel\n",
    "import torch\n",
    "from recbole.data.interaction import Interaction\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from logging import getLogger\n",
    "from collections import defaultdict\n",
    "from recbole.config import Config\n",
    "from recbole.utils import init_seed, init_logger\n",
    "from recbole.data import create_dataset, data_preparation\n",
    "from recbole.trainer import Trainer\n",
    "from recbole.quick_start import load_data_and_model\n",
    "from recbole.model.sequential_recommender import GRU4Rec\n",
    "\n",
    "config = Config(model='GRU4Rec', dataset='gru', config_dict=parameter_dict) # dataset的名字要和文件夹名字一致\n",
    "init_seed(config['seed'], config['reproducibility'])\n",
    "\n",
    "# logger initialization\n",
    "init_logger(config)\n",
    "logger = getLogger()\n",
    "\n",
    "# Create handlers\n",
    "c_handler = logging.StreamHandler()\n",
    "c_handler.setLevel(logging.INFO)\n",
    "logger.addHandler(c_handler)\n",
    "\n",
    "# write config info into log\n",
    "logger.info(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28 Jan 17:42    INFO  Saving filtered dataset into [/root/autodl-tmp/ottodata/tmp/gru_train//gru/gru-dataset.pth]\n",
      "Saving filtered dataset into [/root/autodl-tmp/ottodata/tmp/gru_train//gru/gru-dataset.pth]\n",
      "28 Jan 17:42    INFO  gru\n",
      "The number of users: 2874632\n",
      "Average actions of users: 18.130091827438026\n",
      "The number of items: 957239\n",
      "Average actions of items: 54.44552347483071\n",
      "The number of inters: 52117324\n",
      "The sparsity of the dataset: 99.99810600220839%\n",
      "Remain Fields: ['session', 'aid', 'ts']\n",
      "gru\n",
      "The number of users: 2874632\n",
      "Average actions of users: 18.130091827438026\n",
      "The number of items: 957239\n",
      "Average actions of items: 54.44552347483071\n",
      "The number of inters: 52117324\n",
      "The sparsity of the dataset: 99.99810600220839%\n",
      "Remain Fields: ['session', 'aid', 'ts']\n"
     ]
    }
   ],
   "source": [
    "dataset = create_dataset(config)\n",
    "logger.info(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28 Jan 17:53    INFO  Saving split dataloaders into: [/root/autodl-tmp/ottodata/tmp/gru_train//gru/gru-for-GRU4Rec-dataloader.pth]\n",
      "Saving split dataloaders into: [/root/autodl-tmp/ottodata/tmp/gru_train//gru/gru-for-GRU4Rec-dataloader.pth]\n",
      "28 Jan 17:53    INFO  [Training]: train_batch_size = [2048] negative sampling: [{'uniform': 1}]\n",
      "[Training]: train_batch_size = [2048] negative sampling: [{'uniform': 1}]\n",
      "28 Jan 17:53    INFO  [Evaluation]: eval_batch_size = [1024] eval_args: [{'split': {'RS': [9, 1, 0]}, 'group_by': 'user', 'order': 'TO', 'mode': 'full'}]\n",
      "[Evaluation]: eval_batch_size = [1024] eval_args: [{'split': {'RS': [9, 1, 0]}, 'group_by': 'user', 'order': 'TO', 'mode': 'full'}]\n"
     ]
    }
   ],
   "source": [
    "# dataset splitting\n",
    "train_data, valid_data, test_data = data_preparation(config, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28 Jan 17:53    INFO  GRU4Rec(\n",
      "  (item_embedding): Embedding(957239, 64, padding_idx=0)\n",
      "  (emb_dropout): Dropout(p=0.3, inplace=False)\n",
      "  (gru_layers): GRU(64, 128, bias=False, batch_first=True)\n",
      "  (dense): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (loss_fct): BPRLoss()\n",
      ")\n",
      "Trainable parameters: 61345280\n",
      "GRU4Rec(\n",
      "  (item_embedding): Embedding(957239, 64, padding_idx=0)\n",
      "  (emb_dropout): Dropout(p=0.3, inplace=False)\n",
      "  (gru_layers): GRU(64, 128, bias=False, batch_first=True)\n",
      "  (dense): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (loss_fct): BPRLoss()\n",
      ")\n",
      "Trainable parameters: 61345280\n",
      "28 Jan 18:15    INFO  epoch 0 training [time: 1308.71s, train loss: 3511.2605]\n",
      "epoch 0 training [time: 1308.71s, train loss: 3511.2605]\n",
      "28 Jan 19:38    INFO  epoch 0 evaluating [time: 4937.23s, valid_score: 0.207300]\n",
      "epoch 0 evaluating [time: 4937.23s, valid_score: 0.207300]\n",
      "28 Jan 19:38    INFO  valid result: \n",
      "recall@20 : 0.0624    recall@200 : 0.2073    mrr@20 : 0.0167    mrr@200 : 0.0191    ndcg@20 : 0.0266    ndcg@200 : 0.0503    hit@20 : 0.0624    hit@200 : 0.2073    precision@20 : 0.0031    precision@200 : 0.001\n",
      "valid result: \n",
      "recall@20 : 0.0624    recall@200 : 0.2073    mrr@20 : 0.0167    mrr@200 : 0.0191    ndcg@20 : 0.0266    ndcg@200 : 0.0503    hit@20 : 0.0624    hit@200 : 0.2073    precision@20 : 0.0031    precision@200 : 0.001\n",
      "28 Jan 19:38    INFO  Saving current: /root/autodl-tmp/ottodata/tmp/gru_train//gru/GRU4Rec-Jan-28-2023_17-53-59.pth\n",
      "Saving current: /root/autodl-tmp/ottodata/tmp/gru_train//gru/GRU4Rec-Jan-28-2023_17-53-59.pth\n",
      "28 Jan 19:59    INFO  epoch 1 training [time: 1306.17s, train loss: 1213.1125]\n",
      "epoch 1 training [time: 1306.17s, train loss: 1213.1125]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m/root/suzhaopei/otto/GRU4Rec.ipynb Cell 10\u001B[0m in \u001B[0;36m<cell line: 9>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B123.125.240.150/root/suzhaopei/otto/GRU4Rec.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001B[0m trainer \u001B[39m=\u001B[39m Trainer(config, model)\n\u001B[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B123.125.240.150/root/suzhaopei/otto/GRU4Rec.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001B[0m \u001B[39m# model training\u001B[39;00m\n\u001B[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B123.125.240.150/root/suzhaopei/otto/GRU4Rec.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001B[0m best_valid_score, best_valid_result \u001B[39m=\u001B[39m trainer\u001B[39m.\u001B[39;49mfit(train_data, valid_data)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.8/site-packages/recbole/trainer/trainer.py:352\u001B[0m, in \u001B[0;36mTrainer.fit\u001B[0;34m(self, train_data, valid_data, verbose, saved, show_progress, callback_fn)\u001B[0m\n\u001B[1;32m    350\u001B[0m \u001B[39mif\u001B[39;00m (epoch_idx \u001B[39m+\u001B[39m \u001B[39m1\u001B[39m) \u001B[39m%\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39meval_step \u001B[39m==\u001B[39m \u001B[39m0\u001B[39m:\n\u001B[1;32m    351\u001B[0m     valid_start_time \u001B[39m=\u001B[39m time()\n\u001B[0;32m--> 352\u001B[0m     valid_score, valid_result \u001B[39m=\u001B[39m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_valid_epoch(valid_data, show_progress\u001B[39m=\u001B[39;49mshow_progress)\n\u001B[1;32m    353\u001B[0m     \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mbest_valid_score, \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mcur_step, stop_flag, update_flag \u001B[39m=\u001B[39m early_stopping(\n\u001B[1;32m    354\u001B[0m         valid_score,\n\u001B[1;32m    355\u001B[0m         \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mbest_valid_score,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    358\u001B[0m         bigger\u001B[39m=\u001B[39m\u001B[39mself\u001B[39m\u001B[39m.\u001B[39mvalid_metric_bigger\n\u001B[1;32m    359\u001B[0m     )\n\u001B[1;32m    360\u001B[0m     valid_end_time \u001B[39m=\u001B[39m time()\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.8/site-packages/recbole/trainer/trainer.py:209\u001B[0m, in \u001B[0;36mTrainer._valid_epoch\u001B[0;34m(self, valid_data, show_progress)\u001B[0m\n\u001B[1;32m    198\u001B[0m \u001B[39mdef\u001B[39;00m \u001B[39m_valid_epoch\u001B[39m(\u001B[39mself\u001B[39m, valid_data, show_progress\u001B[39m=\u001B[39m\u001B[39mFalse\u001B[39;00m):\n\u001B[1;32m    199\u001B[0m     \u001B[39mr\u001B[39m\u001B[39m\"\"\"Valid the model with valid data\u001B[39;00m\n\u001B[1;32m    200\u001B[0m \n\u001B[1;32m    201\u001B[0m \u001B[39m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    207\u001B[0m \u001B[39m        dict: valid result\u001B[39;00m\n\u001B[1;32m    208\u001B[0m \u001B[39m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 209\u001B[0m     valid_result \u001B[39m=\u001B[39m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mevaluate(valid_data, load_best_model\u001B[39m=\u001B[39;49m\u001B[39mFalse\u001B[39;49;00m, show_progress\u001B[39m=\u001B[39;49mshow_progress)\n\u001B[1;32m    210\u001B[0m     valid_score \u001B[39m=\u001B[39m calculate_valid_score(valid_result, \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mvalid_metric)\n\u001B[1;32m    211\u001B[0m     \u001B[39mreturn\u001B[39;00m valid_score, valid_result\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001B[0m, in \u001B[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[39m@functools\u001B[39m\u001B[39m.\u001B[39mwraps(func)\n\u001B[1;32m     25\u001B[0m \u001B[39mdef\u001B[39;00m \u001B[39mdecorate_context\u001B[39m(\u001B[39m*\u001B[39margs, \u001B[39m*\u001B[39m\u001B[39m*\u001B[39mkwargs):\n\u001B[1;32m     26\u001B[0m     \u001B[39mwith\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mclone():\n\u001B[0;32m---> 27\u001B[0m         \u001B[39mreturn\u001B[39;00m func(\u001B[39m*\u001B[39;49margs, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mkwargs)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.8/site-packages/recbole/trainer/trainer.py:478\u001B[0m, in \u001B[0;36mTrainer.evaluate\u001B[0;34m(self, eval_data, load_best_model, model_file, show_progress)\u001B[0m\n\u001B[1;32m    476\u001B[0m     \u001B[39mif\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mgpu_available \u001B[39mand\u001B[39;00m show_progress:\n\u001B[1;32m    477\u001B[0m         iter_data\u001B[39m.\u001B[39mset_postfix_str(set_color(\u001B[39m'\u001B[39m\u001B[39mGPU RAM: \u001B[39m\u001B[39m'\u001B[39m \u001B[39m+\u001B[39m get_gpu_usage(\u001B[39mself\u001B[39m\u001B[39m.\u001B[39mdevice), \u001B[39m'\u001B[39m\u001B[39myellow\u001B[39m\u001B[39m'\u001B[39m))\n\u001B[0;32m--> 478\u001B[0m     \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49meval_collector\u001B[39m.\u001B[39;49meval_batch_collect(scores, interaction, positive_u, positive_i)\n\u001B[1;32m    479\u001B[0m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39meval_collector\u001B[39m.\u001B[39mmodel_collect(\u001B[39mself\u001B[39m\u001B[39m.\u001B[39mmodel)\n\u001B[1;32m    480\u001B[0m struct \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39meval_collector\u001B[39m.\u001B[39mget_data_struct()\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.8/site-packages/recbole/evaluator/collector.py:153\u001B[0m, in \u001B[0;36mCollector.eval_batch_collect\u001B[0;34m(self, scores_tensor, interaction, positive_u, positive_i)\u001B[0m\n\u001B[1;32m    151\u001B[0m     pos_idx \u001B[39m=\u001B[39m torch\u001B[39m.\u001B[39mgather(pos_matrix, dim\u001B[39m=\u001B[39m\u001B[39m1\u001B[39m, index\u001B[39m=\u001B[39mtopk_idx)\n\u001B[1;32m    152\u001B[0m     result \u001B[39m=\u001B[39m torch\u001B[39m.\u001B[39mcat((pos_idx, pos_len_list), dim\u001B[39m=\u001B[39m\u001B[39m1\u001B[39m)\n\u001B[0;32m--> 153\u001B[0m     \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mdata_struct\u001B[39m.\u001B[39;49mupdate_tensor(\u001B[39m'\u001B[39;49m\u001B[39mrec.topk\u001B[39;49m\u001B[39m'\u001B[39;49m, result)\n\u001B[1;32m    155\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mregister\u001B[39m.\u001B[39mneed(\u001B[39m'\u001B[39m\u001B[39mrec.meanrank\u001B[39m\u001B[39m'\u001B[39m):\n\u001B[1;32m    157\u001B[0m     desc_scores, desc_index \u001B[39m=\u001B[39m torch\u001B[39m.\u001B[39msort(scores_tensor, dim\u001B[39m=\u001B[39m\u001B[39m-\u001B[39m\u001B[39m1\u001B[39m, descending\u001B[39m=\u001B[39m\u001B[39mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.8/site-packages/recbole/evaluator/collector.py:51\u001B[0m, in \u001B[0;36mDataStruct.update_tensor\u001B[0;34m(self, name, value)\u001B[0m\n\u001B[1;32m     49\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mnot\u001B[39;00m \u001B[39misinstance\u001B[39m(\u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_data_dict[name], torch\u001B[39m.\u001B[39mTensor):\n\u001B[1;32m     50\u001B[0m     \u001B[39mraise\u001B[39;00m \u001B[39mValueError\u001B[39;00m(\u001B[39m\"\u001B[39m\u001B[39m{}\u001B[39;00m\u001B[39m is not a tensor.\u001B[39m\u001B[39m\"\u001B[39m\u001B[39m.\u001B[39mformat(name))\n\u001B[0;32m---> 51\u001B[0m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_data_dict[name] \u001B[39m=\u001B[39m torch\u001B[39m.\u001B[39;49mcat((\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_data_dict[name], value\u001B[39m.\u001B[39;49mcpu()\u001B[39m.\u001B[39;49mclone()\u001B[39m.\u001B[39;49mdetach()), dim\u001B[39m=\u001B[39;49m\u001B[39m0\u001B[39;49m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# model loading and initialization\n",
    "model = GRU4Rec(config, train_data.dataset).to(config['device'])\n",
    "logger.info(model)\n",
    "\n",
    "# trainer loading and initialization\n",
    "trainer = Trainer(config, model)\n",
    "\n",
    "# model training\n",
    "best_valid_score, best_valid_result = trainer.fit(train_data, valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del trainer, train_data, valid_data, test_data\n",
    "gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用训练好的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://qiita.com/fufufukakaka/items/e03df3a7299b2b8f99cf\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from recbole.data import create_dataset\n",
    "from recbole.data.dataset.sequential_dataset import SequentialDataset\n",
    "from recbole.data.interaction import Interaction\n",
    "from recbole.model.sequential_recommender.sine import SINE\n",
    "from recbole.utils import get_model, init_seed\n",
    "\n",
    "class ItemHistory(BaseModel):\n",
    "    sequence: List[str]\n",
    "    topk: int\n",
    "\n",
    "class RecommendedItems(BaseModel):\n",
    "    score_list: List[float]\n",
    "    item_list: List[str]\n",
    "\n",
    "def pred_user_to_item(item_history: ItemHistory, get_emb=None):\n",
    "    item_history_dict = item_history.dict()\n",
    "    item_sequence = item_history_dict[\"sequence\"]  # sequence is AIDs\n",
    "    item_length = len(item_sequence)\n",
    "    pad_length = MAX_ITEM  \n",
    "\n",
    "    '''\n",
    "    First, we need to use token2id() to convert external user id \n",
    "    into internal user id.\n",
    "    Then, we create a 0 padded tensor to pass into the interaction object. \n",
    "    The number of 0s depends on the length of the original item list. \n",
    "    If there are 4 items, then its padded with 16 0s so that the total \n",
    "    length is 20, which is what we want to predict.\n",
    "    '''\n",
    "    # 不足 MAX_ITEM 个候选的用0填充\n",
    "    padded_item_sequence = torch.nn.functional.pad(\n",
    "        torch.tensor(dataset.token2id(dataset.iid_field, item_sequence)),\n",
    "        (0, pad_length - item_length),\n",
    "        \"constant\",\n",
    "        0,\n",
    "    )\n",
    "\n",
    "    '''To perform prediction, we need to create the sequence in this\n",
    "    interaction object.'''        \n",
    "    input_interaction = Interaction(\n",
    "        {\n",
    "            \"aid_list\": padded_item_sequence.reshape(1, -1),\n",
    "            \"item_length\": torch.tensor([item_length]),\n",
    "        }\n",
    "    )\n",
    "    '''\n",
    "    In full_sort_predict, first we pass the sequence forward in the model to get the next article.\n",
    "    This forward pass gives us an embedding. We multiple this embedding with the embedding space \n",
    "    learnt by the model. This matrix multiplication gives us a single score for each item. The higher \n",
    "    the score, the closer that article is to the predicted embedding. \n",
    "    '''\n",
    "    if get_emb == True:\n",
    "        seq_output = model(input_interaction['aid_list'].to(model.device),input_interaction['item_length'].to(model.device))\n",
    "        # print(f'seq_output.shape:{seq_output.shape}')  # bs, emb_size (1,64)\n",
    "        seq_output = seq_output.detach().cpu().numpy().tolist()\n",
    "        return seq_output\n",
    "    else:\n",
    "        scores = model.full_sort_predict(input_interaction.to(model.device))\n",
    "        # print(f'scores.shape {scores.shape}') # torch.Size([1, 450570])\n",
    "\n",
    "        # print(f'dataset.item_num: {dataset.item_num}')  # 450570\n",
    "        scores = scores.view(-1, dataset.item_num)\n",
    "        scores[:, 0] = -np.inf  # pad item score -> -inf\n",
    "\n",
    "        '''Top 20 scores and items are selected using torch.topk.'''\n",
    "        topk_score, topk_iid_list = torch.topk(scores, item_history_dict[\"topk\"])\n",
    "\n",
    "        predicted_score_list = topk_score.tolist()[0]\n",
    "        '''Predicted items need to be translated back into original article IDs \n",
    "        using dataset.id2token.'''\n",
    "        predicted_item_list = dataset.id2token(\n",
    "            dataset.iid_field, topk_iid_list.tolist()\n",
    "        ).tolist()\n",
    "\n",
    "        recommended_items = {\n",
    "            \"score_list\": predicted_score_list,\n",
    "            \"item_list\": predicted_item_list,\n",
    "        }\n",
    "        return recommended_items\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!! 是否生成embedding\n",
    "get_emb = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pl.read_parquet(f'../data/test.parquet')\n",
    "# test_df = test_df[:1000]  # debug\n",
    "\n",
    "# session_types = ['clicks', 'carts', 'orders']\n",
    "test_session_AIDs = test_df.to_pandas().reset_index(drop=True).groupby('session')['aid'].apply(list)\n",
    "test_session_types = test_df.to_pandas().reset_index(drop=True).groupby('session')['type'].apply(list)\n",
    "del test_df\n",
    "labels = []\n",
    "embedding = []\n",
    "type_weight_multipliers = {0: 1, 1: 6, 2: 3}\n",
    "for AIDs, types in zip(test_session_AIDs, test_session_types):\n",
    "    # if len(AIDs) >= MAX_ITEM:\n",
    "    #     # if we have enough aids (over equals 20) we don't need to look for candidates! we just use the old logic\n",
    "    #     weights=np.logspace(0.1,1,len(AIDs),base=2, endpoint=True)-1  # logspac用于创建等比数列,开始点和结束点是10的幂\n",
    "    #     aids_temp=defaultdict(lambda: 0)\n",
    "    #     for aid,w,t in zip(AIDs,weights,types): \n",
    "    #         aids_temp[aid]+= w * type_weight_multipliers[t]\n",
    "            \n",
    "    #     sorted_aids=[k for k, v in sorted(aids_temp.items(), key=lambda item: -item[1])]  \n",
    "    #     labels.append(sorted_aids[:MAX_ITEM])\n",
    "    #     if get_emb:\n",
    "    #         try:\n",
    "    #             emb = pred_user_to_item(item, MAX_ITEM, get_emb=True)\n",
    "    #         except:\n",
    "    #             emb = []\n",
    "    # else:\n",
    "    AIDs = list(dict.fromkeys(AIDs))\n",
    "    item = ItemHistory(sequence=AIDs, topk=MAX_ITEM)\n",
    "    try:\n",
    "        nns = [int(v) for v in pred_user_to_item(item, MAX_ITEM)['item_list']]\n",
    "    except:\n",
    "        nns = []\n",
    "\n",
    "    for word in nns:\n",
    "        if len(AIDs) == MAX_ITEM:\n",
    "            break\n",
    "        if int(word) not in AIDs:\n",
    "            AIDs.append(word)\n",
    "\n",
    "    labels.append(AIDs[:MAX_ITEM])\n",
    "\n",
    "    if get_emb:\n",
    "        try:\n",
    "            emb = pred_user_to_item(item, MAX_ITEM, get_emb=True)\n",
    "        except:\n",
    "            emb = []\n",
    "    if get_emb:\n",
    "        if len(emb) != 0: \n",
    "            embedding.append(emb[0])  # emb\n",
    "        else:\n",
    "            embedding.append(emb)\n",
    "\n",
    "if get_emb:\n",
    "    emb_df = pd.DataFrame(data={'session': test_session_AIDs.index, 'emb': embedding})\n",
    "    if IS_TRAIN:\n",
    "        # print(f'emb_df:::::{emb_df}')\n",
    "        emb_df.to_parquet(f'/root/autodl-tmp/ottodata/tmp/gru_{MAX_ITEM}_emb_train.parquet')\n",
    "    else:\n",
    "        emb_df.to_parquet(f'/root/autodl-tmp/ottodata/tmp/gru_{MAX_ITEM}_emb_test.parquet')\n",
    "\n",
    "data = pd.DataFrame(data={'session': test_session_AIDs.index, 'aid': labels})  \n",
    "df = pl.DataFrame(data)\n",
    "df = df.explode('aid') \n",
    "df = df.select([pl.col('session').cast(pl.Int32), pl.col('aid').cast(pl.Int32)])\n",
    "if IS_TRAIN:\n",
    "    df.write_parquet(f'/root/autodl-tmp/ottodata/tmp/gru_{MAX_ITEM}_train.parquet')  # 粗排的候选\n",
    "else:\n",
    "    df.write_parquet(f'/root/autodl-tmp/ottodata/tmp/gru_{MAX_ITEM}_test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Jun  4 2021, 15:09:15) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2f394aca7ca06fed1e6064aef884364492d7cdda3614a461e02e6407fc40ba69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
